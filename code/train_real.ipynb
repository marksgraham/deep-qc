{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize, imrotate\n",
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input, InceptionV3\n",
    "from keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "import keras.backend as K\n",
    "from keras import models\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from time import gmtime, strftime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "root_dir = os.path.abspath('..')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def fetch_real_data(base_dir,num_subjects):\n",
    "    '''Load in simulated data and motion files.'''\n",
    "    subject_list = os.listdir((os.path.join(base_dir)))\n",
    "    subject_list = [item for item in subject_list if item.startswith('sub') == True] #Filter everything but subjects\n",
    "    subject_list = sorted(subject_list) #sort in numerical order to make OS independent\n",
    "    counter = 0\n",
    "    num_vols=172\n",
    "    X = np.zeros((num_vols*num_subjects,128,128,64))\n",
    "    y = np.zeros(num_vols*num_subjects)\n",
    "    X_subject = np.zeros((128,128,64,num_vols))\n",
    "    y_subject = np.zeros(num_vols)\n",
    "    for subject_index, subject_number in enumerate(subject_list):\n",
    "        if subject_index < num_subjects:\n",
    "            data_path = os.path.join(base_dir,subject_number,'dwi.nii.gz')\n",
    "            if os.path.isfile(data_path):\n",
    "                data_header = nib.load(data_path)\n",
    "                X_subject = data_header.get_data()\n",
    "                y_subject = np.load(os.path.join(base_dir,subject_number,'y_manual.npy'))\n",
    "                start_index = counter*num_vols\n",
    "                end_index = (counter+1)*num_vols\n",
    "                X[start_index:end_index,:] = np.moveaxis(X_subject,3,0)\n",
    "                y[start_index:end_index] = y_subject\n",
    "                counter += 1\n",
    "    return X,y\n",
    "\n",
    "def preprocess_data_coronal(X,target_height=299,target_width=299, base_slice=64,rescale=False,):\n",
    "    '''Convert each MR volume to three slices through a single plane, scales the data and resamples\n",
    "    to 299 by 299 pixels. Optionally performs augmentation.'''   \n",
    "    #slices = [22,36,50] #Planes to slice\n",
    "    slices = np.array([base_slice,base_slice,base_slice]) #Planes to slice\n",
    "    pad_max = np.max([X.shape[1],X.shape[3]]) #Width to pad images to\n",
    "    \n",
    "    num_volumes = X.shape[0]\n",
    "    height = X.shape[1]\n",
    "    width = X.shape[3]\n",
    "    num_slices = X.shape[2]\n",
    "    X_preprocessed = np.zeros((num_volumes,target_height,target_width,3))\n",
    "\n",
    "    for i in range(num_volumes):\n",
    "        for j in range(3):\n",
    "            if (j == 0):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,:,slices[j],:]),pad_max),(target_width,target_height))\n",
    "            if (j == 1):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,:,slices[j],:]),pad_max),(target_width,target_height))\n",
    "            if (j == 2):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,:,slices[j],:]),pad_max),(target_width,target_height))     \n",
    "   \n",
    "    if rescale == True:\n",
    "        X_preprocessed = X_preprocessed.astype(np.float32)\n",
    "        X_preprocessed/= 255\n",
    "        X_preprocessed -= 0.5\n",
    "        X_preprocessed *= 2.\n",
    "    return X_preprocessed\n",
    "\n",
    "def preprocess_data_saggital(X,target_height=299,target_width=299, base_slice=64,rescale=False,):\n",
    "    '''Convert each MR volume to three slices through a single plane, scales the data and resamples\n",
    "    to 299 by 299 pixels. Optionally performs augmentation.'''   \n",
    "    #slices = [22,36,50] #Planes to slice\n",
    "    slices = np.array([base_slice,base_slice,base_slice]) #Planes to slice\n",
    "    pad_max = np.max([X.shape[1],X.shape[3]]) #Width to pad images to\n",
    "    \n",
    "    num_volumes = X.shape[0]\n",
    "    height = X.shape[1]\n",
    "    width = X.shape[2]\n",
    "    num_slices = X.shape[3]\n",
    "    X_preprocessed = np.zeros((num_volumes,target_height,target_width,3))\n",
    "\n",
    "    for i in range(num_volumes):\n",
    "        for j in range(3):\n",
    "            if (j == 0):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,slices[j],:,:]),pad_max),(target_width,target_height))\n",
    "            if (j == 1):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,slices[j],:,:]),pad_max),(target_width,target_height))\n",
    "            if (j == 2):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,slices[j],:,:]),pad_max),(target_width,target_height))     \n",
    "   \n",
    "    if rescale == True:\n",
    "        X_preprocessed = X_preprocessed.astype(np.float32)\n",
    "        X_preprocessed/= 255\n",
    "        X_preprocessed -= 0.5\n",
    "        X_preprocessed *= 2.\n",
    "    return X_preprocessed\n",
    "\n",
    "def pad_image(image,pad_max):\n",
    "    if pad_max == 0:\n",
    "        return image\n",
    "    else:\n",
    "        pad_width = np.array([[pad_max,pad_max],[pad_max,pad_max]])-[image.shape,image.shape]\n",
    "        pad_width=np.transpose(pad_width)\n",
    "        pad_width[:,0] = np.floor(pad_width[:,0]/2)\n",
    "        pad_width[:,1] = np.ceil(pad_width[:,1]/2)\n",
    "        return np.lib.pad(image,pad_width,'constant',constant_values=(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1376, 128, 128, 64) (1376,)\n",
      "Train shape X (3096, 299, 299, 3)\n",
      "Train shape y (3096, 299, 299, 3)\n",
      "Train shape X (3096, 299, 299, 3)\n",
      "Train shape y (3096,)\n"
     ]
    }
   ],
   "source": [
    "X,y = fetch_real_data('../data/sourcedata/',8)\n",
    "print(X.shape,y.shape)\n",
    "\n",
    "\n",
    "num_vols = 172\n",
    "num_train = 6\n",
    "num_test = 2\n",
    "slices_to_extract = [50,64,80]\n",
    "\n",
    "X_train = np.zeros((num_vols*num_train*len(slices_to_extract),299,299,3))\n",
    "X_test = np.zeros((num_vols*num_test*len(slices_to_extract),299,299,3))\n",
    "y_train = np.zeros((num_vols*num_train*len(slices_to_extract)))\n",
    "y_test = np.zeros((num_vols*num_test*len(slices_to_extract)))\n",
    "\n",
    "for slice_num, slice_indx in enumerate(slices_to_extract):\n",
    "    start_indx_train = slice_num * num_vols*num_train\n",
    "    end_indx_train = (slice_num+1) * num_vols*num_train\n",
    "    start_indx_test = slice_num * num_vols*num_test\n",
    "    end_indx_test = (slice_num+1) * num_vols*num_test\n",
    "    X_preprocessed = preprocess_data_saggital(X,base_slice=slice_indx)\n",
    "    \n",
    "    X_train[start_indx_train:end_indx_train,:] = X_preprocessed[:num_vols*num_train]\n",
    "    X_test[start_indx_test:end_indx_test,:] = X_preprocessed[num_vols*num_train:]\n",
    "    y_train[start_indx_train:end_indx_train]= y[:num_vols*num_train]\n",
    "    y_test[start_indx_test:end_indx_test]=y[num_vols*num_train:]\n",
    "\n",
    "y_train = (y_train!=0)\n",
    "y_test = (y_test!=0)\n",
    "\n",
    "print('Train shape X',X_train.shape)\n",
    "print('Train shape y',X_train.shape)\n",
    "\n",
    "print('Test shape X',X_test.shape)\n",
    "print('Test shape y',y_test.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "slice_=30\n",
    "X_test = preprocess_data_coronal(X[:,20:110,:,:],base_slice=slice_)\n",
    "\n",
    "pos_indices = np.where(y!=0)[0]\n",
    "index=41\n",
    "index2 = pos_indices[index]\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X[index2,:,slice_,:])\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X_test[index2,:,:,0])\n",
    "print(y[index2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "train_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    data_format='channels_last')\n",
    "\n",
    "validation_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    data_format='channels_last',)\n",
    "\n",
    "train_batch_size = 43\n",
    "validation_batch_size = 43\n",
    "train_examples = X_train.shape[0]\n",
    "validation_examples = X_test.shape[0]\n",
    "train_data = train_generator.flow(X_train,to_categorical(y_train,2),batch_size=train_batch_size,shuffle=True)\n",
    "validation_data = validation_generator.flow(X_test,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "\n",
    "\n",
    "#     ctr = 0\n",
    "#     for batch in train_data:\n",
    "#         im = np.squeeze(batch[0][6,:])\n",
    "#         print(im.shape)\n",
    "#         plt.imshow(im)\n",
    "#         ctr += 1\n",
    "#         if ctr > 0:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863372093023\n",
      "423\n",
      "0.735465116279\n",
      "273\n"
     ]
    }
   ],
   "source": [
    "print(1-np.sum(y_train)/len(y_train))\n",
    "print(np.sum(y_train))\n",
    "print(1-np.sum(y_test)/len(y_test))\n",
    "print(np.sum(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "86827008/87910968 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "#Set up inception v3 for transfer learning\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(16,activation='relu')(x)\n",
    "predictions = Dense(2,activation='softmax')(x)\n",
    "\n",
    "\n",
    "    \n",
    "model = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "                 metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.0\n",
      "24.0\n",
      "Model name: keras_logs/2017-10-11-14-38-31\n",
      "Epoch 1/30\n",
      "72/72 [==============================] - 68s - loss: 0.3414 - acc: 0.8576 - val_loss: 0.3907 - val_acc: 0.7510\n",
      "Epoch 2/30\n",
      "72/72 [==============================] - 65s - loss: 0.1928 - acc: 0.9196 - val_loss: 0.3459 - val_acc: 0.8014\n",
      "Epoch 3/30\n",
      "72/72 [==============================] - 65s - loss: 0.1738 - acc: 0.9467 - val_loss: 0.2972 - val_acc: 0.8721\n",
      "Epoch 4/30\n",
      "72/72 [==============================] - 65s - loss: 0.1605 - acc: 0.9574 - val_loss: 0.3038 - val_acc: 0.8702\n",
      "Epoch 5/30\n",
      "72/72 [==============================] - 65s - loss: 0.1517 - acc: 0.9609 - val_loss: 0.2401 - val_acc: 0.9360\n",
      "Epoch 6/30\n",
      "72/72 [==============================] - 65s - loss: 0.1441 - acc: 0.9645 - val_loss: 0.3229 - val_acc: 0.8537\n",
      "Epoch 7/30\n",
      "72/72 [==============================] - 65s - loss: 0.1456 - acc: 0.9612 - val_loss: 0.2693 - val_acc: 0.9012\n",
      "Epoch 8/30\n",
      "72/72 [==============================] - 65s - loss: 0.1263 - acc: 0.9690 - val_loss: 0.2681 - val_acc: 0.9234\n",
      "Epoch 9/30\n",
      "72/72 [==============================] - 65s - loss: 0.1256 - acc: 0.9651 - val_loss: 0.2251 - val_acc: 0.9370\n",
      "Epoch 10/30\n",
      "72/72 [==============================] - 70s - loss: 0.1202 - acc: 0.9677 - val_loss: 0.2407 - val_acc: 0.9254\n",
      "Epoch 11/30\n",
      "72/72 [==============================] - 65s - loss: 0.1227 - acc: 0.9667 - val_loss: 0.2299 - val_acc: 0.9312\n",
      "Epoch 12/30\n",
      "72/72 [==============================] - 65s - loss: 0.1050 - acc: 0.9729 - val_loss: 0.2193 - val_acc: 0.9351\n",
      "Epoch 13/30\n",
      "72/72 [==============================] - 65s - loss: 0.1033 - acc: 0.9725 - val_loss: 0.2350 - val_acc: 0.9196\n",
      "Epoch 14/30\n",
      "72/72 [==============================] - 65s - loss: 0.1100 - acc: 0.9696 - val_loss: 0.2131 - val_acc: 0.9380\n",
      "Epoch 15/30\n",
      "72/72 [==============================] - 65s - loss: 0.1021 - acc: 0.9716 - val_loss: 0.2140 - val_acc: 0.9370\n",
      "Epoch 16/30\n",
      "72/72 [==============================] - 65s - loss: 0.1018 - acc: 0.9706 - val_loss: 0.2210 - val_acc: 0.9264\n",
      "Epoch 17/30\n",
      "72/72 [==============================] - 65s - loss: 0.0881 - acc: 0.9735 - val_loss: 0.2125 - val_acc: 0.9331\n",
      "Epoch 18/30\n",
      "72/72 [==============================] - 65s - loss: 0.0869 - acc: 0.9742 - val_loss: 0.2333 - val_acc: 0.9099\n",
      "Epoch 19/30\n",
      "72/72 [==============================] - 65s - loss: 0.0835 - acc: 0.9755 - val_loss: 0.2099 - val_acc: 0.9341\n",
      "Epoch 20/30\n",
      "72/72 [==============================] - 66s - loss: 0.0901 - acc: 0.9751 - val_loss: 0.2897 - val_acc: 0.8740\n",
      "Epoch 21/30\n",
      "72/72 [==============================] - 65s - loss: 0.0853 - acc: 0.9738 - val_loss: 0.2062 - val_acc: 0.9380\n",
      "Epoch 22/30\n",
      "72/72 [==============================] - 65s - loss: 0.0762 - acc: 0.9761 - val_loss: 0.2046 - val_acc: 0.9360\n",
      "Epoch 23/30\n",
      "72/72 [==============================] - 65s - loss: 0.0727 - acc: 0.9784 - val_loss: 0.2054 - val_acc: 0.9399\n",
      "Epoch 24/30\n",
      "72/72 [==============================] - 65s - loss: 0.0723 - acc: 0.9784 - val_loss: 0.2137 - val_acc: 0.9293\n",
      "Epoch 25/30\n",
      "72/72 [==============================] - 65s - loss: 0.0673 - acc: 0.9787 - val_loss: 0.2172 - val_acc: 0.9370\n",
      "Epoch 26/30\n",
      "72/72 [==============================] - 65s - loss: 0.0649 - acc: 0.9803 - val_loss: 0.2590 - val_acc: 0.8934\n",
      "Epoch 27/30\n",
      "72/72 [==============================] - 65s - loss: 0.0712 - acc: 0.9790 - val_loss: 0.2565 - val_acc: 0.8983\n",
      "Epoch 28/30\n",
      "72/72 [==============================] - 65s - loss: 0.0646 - acc: 0.9819 - val_loss: 0.2793 - val_acc: 0.8837\n",
      "Epoch 29/30\n",
      "72/72 [==============================] - 65s - loss: 0.0656 - acc: 0.9790 - val_loss: 0.2208 - val_acc: 0.9215\n",
      "Epoch 30/30\n",
      "72/72 [==============================] - 66s - loss: 0.0578 - acc: 0.9842 - val_loss: 0.2270 - val_acc: 0.9186\n",
      "[[688  71]\n",
      " [ 13 260]]\n"
     ]
    }
   ],
   "source": [
    "now = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "filename = 'keras_logs/real_'+now+'.epoch{epoch:02d}-lossval{val_loss:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filename,\n",
    "                            period=10)\n",
    "\n",
    "train_steps_per_epoch = train_examples/train_batch_size\n",
    "validation_steps_per_epoch = validation_examples/validation_batch_size\n",
    "print(train_steps_per_epoch)\n",
    "print(validation_steps_per_epoch)\n",
    "num_epochs = 30\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Model name:','real_keras_logs/'+now)\n",
    "history = model.fit_generator(generator = train_data,\n",
    "                           steps_per_epoch=train_steps_per_epoch,\n",
    "                           epochs = num_epochs,\n",
    "                           validation_data = validation_data,\n",
    "                           validation_steps = validation_steps_per_epoch,\n",
    "                           class_weight=[1,5],\n",
    "                            callbacks=[checkpoint])\n",
    "\n",
    "validation_data = validation_generator.flow(X_test,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "y_pred = model.predict_generator(validation_data,validation_steps_per_epoch)[:,1] > 0.5\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Get predictions for many slices of the train set\n",
    "validation_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.0,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    data_format='channels_last',)\n",
    "\n",
    "model_coronal =   models.load_model('keras_logs/coronal_model.hdf5')\n",
    "model_saggital =   models.load_model('keras_logs/saggital_model.hdf5')\n",
    "\n",
    "#Free up some mem\n",
    "#del X_train, X_test\n",
    "num_slices = 30\n",
    "\n",
    "num_volumes = 648\n",
    "X, y = fetch_data(os.path.join(root_dir,'data/sims'),8)\n",
    "y_train = y[:num_volumes]\n",
    "X_train = X[:num_volumes,:,:,:]\n",
    "del X, y\n",
    "\n",
    "validation_batch_size = 54\n",
    "num_generator_steps = int(num_volumes/validation_batch_size)\n",
    "\n",
    "model_predictions_coronal_train = np.zeros((num_volumes,num_slices))\n",
    "model_predictions_saggital_train = np.zeros((num_volumes,num_slices))\n",
    "\n",
    "for i in range(num_slices):\n",
    "    #coronal\n",
    "    X_test_slice = preprocess_data_coronal(X_train,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_test_slice,y_train,batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_coronal_train[:,i] = model_coronal.predict_generator(validation_data_for_testing,num_generator_steps)[:,1]\n",
    "    del X_test_slice\n",
    "    \n",
    "    #saggital\n",
    "    X_test_slice = preprocess_data_planar(X_train,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_test_slice,y_train,batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_saggital_train[:,i] = model_saggital.predict_generator(validation_data_for_testing,num_generator_steps)[:,1]\n",
    "    del X_test_slice\n",
    "    print('Slices complete:',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Train classifier on predictions and gt\n",
    "\n",
    "svm_classifier = SVC(kernel='linear')\n",
    "predictions_combined_train = np.concatenate((model_predictions_coronal_train,model_predictions_saggital_train),axis=1)\n",
    "#predictions_combined_train = model_predictions_coronal_train\n",
    "svm_classifier.fit(predictions_combined_train,y_train)\n",
    "y_pred = svm_classifier.predict(predictions_combined_train)\n",
    "print(accuracy_score(y_train,y_pred))\n",
    "print(confusion_matrix(y_train,y_pred))\n",
    "\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=3)\n",
    "rf_classifier.fit(predictions_combined_train,y_train)\n",
    "y_pred_rf = rf_classifier.predict(predictions_combined_train)\n",
    "print(accuracy_score(y_train,y_pred_rf))\n",
    "print(confusion_matrix(y_train,y_pred_rf))\n",
    "\n",
    "#Save relevant files\n",
    "\n",
    "np.save('misc_files/predictions_combined_train',predictions_combined_train)\n",
    "np.save('misc_files/y_train',y_train)\n",
    "joblib.dump(svm_classifier, 'misc_files/svm_classifier.pkl') \n",
    "joblib.dump(rf_classifier, 'misc_files/rf_classifier.pkl') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Test on many slices of validation set\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras import models\n",
    "#from sklearn.model_selection import accuracy\n",
    "\n",
    "#model_coronal =   models.load_model('keras_logs/coronal_model.hdf5')\n",
    "#model_saggital=   models.load_model('keras_logs/saggital_model.hdf5')\n",
    "model_coronal =   models.load_model('keras_logs/2017-10-05-14-39-37.epoch29-lossval0.29.hdf5')\n",
    "model_saggital =   models.load_model('keras_logs/2017-10-05-13-58-21.epoch29-lossval0.20.hdf5')\n",
    "\n",
    "#Free up some mem\n",
    "#del X_train, X_test\n",
    "X, y = fetch_data(os.path.join(root_dir,'data/sims'),10)\n",
    "num_volumes = 216\n",
    "y_val = y[864:]\n",
    "X_val = X[864:,:,:,:]\n",
    "print(y_val.shape)\n",
    "del X, y\n",
    "\n",
    "num_slices = 30\n",
    "validation_batch_size = 43\n",
    "num_generator_steps = int(num_volumes/validation_batch_size)\n",
    "\n",
    "model_predictions_coronal_val = np.zeros((num_volumes,num_slices))\n",
    "model_predictions_saggital_val = np.zeros((num_volumes,num_slices))\n",
    "\n",
    "for i in range(num_slices):\n",
    "    #coronal\n",
    "    X_val_slice = preprocess_data_coronal(X_val,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_val_slice,to_categorical(y_val,2),batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_coronal_val[:,i] = model_coronal.predict_generator(validation_data_for_testing,num_generator_steps)[:,1]\n",
    "    \n",
    "    #saggital\n",
    "    X_val_slice = preprocess_data_planar(X_val,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_val_slice,to_categorical(y_val,2),batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_saggital_val[:,i] = model_saggital.predict_generator(validation_data_for_testing,num_generator_steps)[:,1]\n",
    "    print('Slices complete:',i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "predictions_combined_val = np.concatenate((model_predictions_coronal_val,model_predictions_saggital_val),axis=1)\n",
    "#predictions_combined_val=model_predictions_saggital_val\n",
    "\n",
    "y_pred_val = np.mean(predictions_combined_val,axis=1)>0.5\n",
    "print(accuracy_score(y_val,y_pred_val))\n",
    "print(confusion_matrix(y_val,y_pred_val))\n",
    "\n",
    "# y_pred_val = svm_classifier.predict(predictions_combined_val)\n",
    "# print(accuracy_score(y_val,y_pred_val))\n",
    "# print(confusion_matrix(y_val,y_pred_val))\n",
    "# y_pred_val_rf = rf_classifier.predict(predictions_combined_val)\n",
    "# print(accuracy_score(y_val,y_pred_val_rf))\n",
    "# print(confusion_matrix(y_val,y_pred_val_rf))\n",
    "\n",
    "#Save relevant files\n",
    "from sklearn.externals import joblib\n",
    "#np.save('misc_files/predictions_combined_val',predictions_combined_val)\n",
    "#np.save('misc_files/y_val',y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slices complete: 0\n",
      "Slices complete: 1\n",
      "Slices complete: 2\n",
      "Slices complete: 3\n",
      "Slices complete: 4\n",
      "Slices complete: 5\n",
      "Slices complete: 6\n",
      "Slices complete: 7\n",
      "Slices complete: 8\n",
      "Slices complete: 9\n",
      "Slices complete: 10\n",
      "Slices complete: 11\n",
      "Slices complete: 12\n",
      "Slices complete: 13\n",
      "Slices complete: 14\n",
      "Slices complete: 15\n",
      "Slices complete: 16\n",
      "Slices complete: 17\n",
      "Slices complete: 18\n",
      "Slices complete: 19\n",
      "Slices complete: 20\n",
      "Slices complete: 21\n",
      "Slices complete: 22\n",
      "Slices complete: 23\n",
      "Slices complete: 24\n",
      "Slices complete: 25\n",
      "Slices complete: 26\n",
      "Slices complete: 27\n",
      "Slices complete: 28\n",
      "Slices complete: 29\n"
     ]
    }
   ],
   "source": [
    "#Try test set \n",
    "#model_coronal =   models.load_model('keras_logs/coronal_model.hdf5')\n",
    "#model_saggital=   models.load_model('keras_logs/saggital_model.hdf5')\n",
    "model_saggital=   model\n",
    "#Free up some mem\n",
    "#del X_train, X_test\n",
    "X,y = fetch_real_data('../data/sourcedata/',10)\n",
    "\n",
    "num_volumes = 172*2\n",
    "y_test = y[172*8:]\n",
    "y_test_cat=y_test!=0\n",
    "X_test = X[172*8:,:,:,:]\n",
    "del X, y\n",
    "num_slices = 30\n",
    "validation_batch_size = 43\n",
    "num_generator_steps = int(num_volumes/validation_batch_size)\n",
    "\n",
    "\n",
    "model_predictions_coronal_test = np.zeros((num_volumes,num_slices))\n",
    "model_predictions_saggital_test = np.zeros((num_volumes,num_slices))\n",
    "\n",
    "for i in range(num_slices):\n",
    "#     #coronal\n",
    "#     X_test_slice = preprocess_data_coronal(X_test,base_slice = 25+i)  \n",
    "#     #Redefine validation generator to reset\n",
    "#     validation_data_for_testing = validation_generator.flow(X_test_slice,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "#     model_predictions_coronal_test[:,i] = model_coronal.predict_generator(validation_data_for_testing,num_generator_steps)[:,1]\n",
    "    \n",
    "    #saggital\n",
    "    X_test_slice = preprocess_data_saggital(X_test,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_test_slice,to_categorical(y_test_cat,2),batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_saggital_test[:,i] = model_saggital.predict_generator(validation_data_for_testing,num_generator_steps)[:,1]\n",
    "    print('Slices complete:',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False       0.99      0.98      0.98       295\n",
      "       True       0.88      0.94      0.91        49\n",
      "\n",
      "avg / total       0.97      0.97      0.97       344\n",
      "\n",
      "[[289   6]\n",
      " [  3  46]]\n"
     ]
    }
   ],
   "source": [
    "#predictions_combined = np.concatenate((model_predictions_coronal_test,model_predictions_saggital_test),axis=1)\n",
    "predictions_combined = model_predictions_saggital_test\n",
    "y_pred = np.mean(predictions_combined,axis=1)>0.6\n",
    "print(classification_report((y_test!=0),y_pred))\n",
    "print(confusion_matrix((y_test!=0),y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Visualise "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Load back in results\n",
    "y_predictions_combined = np.load('misc_files/predictions_combined_val.npy')\n",
    "y_val = np.load('misc_files/y_val.npy')\n",
    "svm_classifier = joblib.load('misc_files/svm_classifier.pkl') \n",
    "#y_pred_val = svm_classifier.predict(y_predictions_combined)\n",
    "y_pred_val = np.mean(y_predictions_combined,axis=1) > 0.5 \n",
    "print(confusion_matrix(y_val,y_pred_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from matplotlib import animation\n",
    "from matplotlib import animation, rc\n",
    "from IPython.display import HTML\n",
    "\n",
    "\n",
    "ind_true_pos = [indx for indx,y in enumerate(y_val) if (y_val[indx] == 1) and (y_pred_val[indx] == 1) ]\n",
    "ind_true_neg = [indx for indx,y in enumerate(y_val) if (y_val[indx] == 0) and (y_pred_val[indx] == 0) ]\n",
    "ind_false_neg = [indx for indx,y in enumerate(y_val) if (y_val[indx] == 1) and (y_pred_val[indx] == 0) ]\n",
    "ind_false_pos = [indx for indx,y in enumerate(y_val) if (y_val[indx] == 0) and (y_pred_val[indx] == 1) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Animated plot of confusion-matrix\n",
    "#X, y = fetch_data(os.path.join(root_dir,'data/sims'),8)\n",
    "X_test_preprocessed = preprocess_data_planar(X[648:,:,:,:])\n",
    "#del X, y\n",
    "\n",
    "X_test_preprocessed_plot = X_test_preprocessed.astype(np.float32)/255\n",
    "#X_test_preprocessed_plot += 0.5\n",
    "\n",
    "fig=plt.figure(figsize=(12,12))\n",
    "ax1 = fig.add_subplot(221)\n",
    "ax2 = fig.add_subplot(222)\n",
    "ax3 = fig.add_subplot(223)\n",
    "ax4 = fig.add_subplot(224)\n",
    "\n",
    "image1 = ax1.imshow(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2],3))); ax1.axis('off')\n",
    "image2 = ax2.imshow(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2],3))); ax2.axis('off')\n",
    "image3 = ax3.imshow(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2],3))); ax3.axis('off')\n",
    "image4 = ax4.imshow(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2],3))); ax4.axis('off')\n",
    "fig.text(0.5, 0.94, 'Predictions', ha='center',weight='bold')\n",
    "fig.text(0.06, 0.5, 'Actual', ha='center',weight='bold')\n",
    "fig.text(0.08, 0.7, 'False', ha='center')\n",
    "fig.text(0.08, 0.3, 'True', ha='center')\n",
    "fig.text(0.32, 0.9, 'False', ha='center')\n",
    "fig.text(0.7, 0.9, 'True', ha='center')\n",
    "fig.text(0.47, 0.52, str(len(ind_true_neg)), ha='center',color='white')\n",
    "fig.text(0.55, 0.52, str(len(ind_false_pos)), ha='center',color='white')\n",
    "fig.text(0.47, 0.45, str(len(ind_false_neg)), ha='center',color='white')\n",
    "fig.text(0.55, 0.45, str(len(ind_true_pos)), ha='center',color='white')\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 20})\n",
    "fig.subplots_adjust(hspace=0.03, wspace=0.02)\n",
    "plt.close()\n",
    "\n",
    "def init():\n",
    "    image1.set_data(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2]))); \n",
    "    image2.set_data(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2])))\n",
    "    image3.set_data(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2])))\n",
    "    image4.set_data(np.zeros((X_test_preprocessed_plot.shape[1],X_test_preprocessed_plot.shape[2])))\n",
    "    \n",
    "    return image1,image2,image3,image4,\n",
    "\n",
    "def animate(i):\n",
    "    image1.set_data(np.rot90(X_test_preprocessed_plot[ind_true_neg[i % len(ind_true_neg)],:]))\n",
    "    image2.set_data(np.rot90(X_test_preprocessed_plot[ind_false_pos[i % len(ind_false_pos)],:]))\n",
    "    image3.set_data(np.rot90(X_test_preprocessed_plot[ind_false_neg[i % len(ind_false_neg)],:]))\n",
    "    image4.set_data(np.rot90(X_test_preprocessed_plot[ind_true_pos[i % len(ind_true_pos)],:]))\n",
    "    return image1,image2,image3,image4,\n",
    "\n",
    "anim = animation.FuncAnimation(fig,animate,init_func=init,frames=40,interval=200,blit=True)\n",
    "mywriter = animation.FFMpegWriter()\n",
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "print(y_test)\n",
    "plt.plot(np.linspace(25,54,30),model_predictions[n])\n",
    "plt.title('True:'+str(y_test[n])+' Predicted:'+str(y_pred[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "  acc = history.history['acc']\n",
    "  val_acc = history.history['val_acc']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'r.')\n",
    "  plt.plot(epochs, val_acc, 'r')\n",
    "  plt.title('Training and validation accuracy')\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'r.')\n",
    "  plt.plot(epochs, val_loss, 'r-')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.show()\n",
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Look at memory usage of all items in notebook\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
