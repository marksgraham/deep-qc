{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.misc import imresize, imrotate\n",
    "%matplotlib inline\n",
    "import keras\n",
    "\n",
    "root_dir = os.path.abspath('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fetch_data(base_dir,num_subjects):\n",
    "    '''Load in simulated data and motion files.'''\n",
    "    subject_list = os.listdir((os.path.join(base_dir)))\n",
    "    subject_list = [item for item in subject_list if item.startswith('.') == False] #Filter .DS_STORE\n",
    "    subject_list = sorted(subject_list) #sort in numerical order to make OS independent\n",
    "    counter = 0\n",
    "    X = np.zeros((108*num_subjects,72,86,55))\n",
    "    y = np.zeros(108*num_subjects)\n",
    "    X_subject = np.zeros((72,86,55,108))\n",
    "    y_subject = np.zeros(108)\n",
    "    print(subject_list)\n",
    "    print(sorted(subject_list))\n",
    "    for subject_index, subject_number in enumerate(subject_list):\n",
    "        if subject_index < num_subjects:\n",
    "            data_path = os.path.join(base_dir,subject_number,'data.nii.gz')\n",
    "            if os.path.isfile(data_path):\n",
    "                data_header = nib.load(data_path)\n",
    "                X_subject = data_header.get_data()\n",
    "                for i in range(108):\n",
    "                    motion = np.loadtxt(os.path.join(base_dir,subject_number,'motion/motion'+str(i)+'.txt'))\n",
    "                    y_subject[i] = create_labels(motion)\n",
    "                start_index = counter*108\n",
    "                end_index = (counter+1)*108\n",
    "                X[start_index:end_index,:] = np.moveaxis(X_subject,3,0)\n",
    "                y[start_index:end_index] = y_subject\n",
    "                counter += 1\n",
    "    return X,y\n",
    "\n",
    "def create_labels(motion, translation_threshold=1, rotation_threshold = 1):\n",
    "    '''Take a POSSUM motion file and decide whether it contains signficant intra-volume movement.'''\n",
    "    max_motion = np.max(motion[:,1:],axis=0)\n",
    "    min_motion = np.min(motion[:,1:],axis=0)\n",
    "    diff_motion = np.abs(max_motion-min_motion)\n",
    "    diff_motion[:3] = diff_motion[:3]*1000\n",
    "    diff_motion[3:] = np.rad2deg(diff_motion[3:])\n",
    "    if np.any( diff_motion[:3] > translation_threshold):\n",
    "        return 1\n",
    "    elif np.any(diff_motion[3:] > rotation_threshold):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "def pad_image(image,pad_max):\n",
    "    if pad_max == 0:\n",
    "        return image\n",
    "    else:\n",
    "        pad_width = np.array([[pad_max,pad_max],[pad_max,pad_max]])-[image.shape,image.shape]\n",
    "        pad_width=np.transpose(pad_width)\n",
    "        pad_width[:,0] = np.floor(pad_width[:,0]/2)\n",
    "        pad_width[:,1] = np.ceil(pad_width[:,1]/2)\n",
    "        return np.lib.pad(image,pad_width,'constant',constant_values=(0))\n",
    "    \n",
    "def preprocess_data_planar(X,target_height=299,target_width=299,is_training=False,\\\n",
    "                           flip=False,rotate_z=False,base_slice=36,sample_more_slices=True,\\\n",
    "                           pad_images=False,crop_image=False,rescale=False):\n",
    "    '''Convert each MR volume to three slices through a single plane, scales the data and resamples\n",
    "    to 299 by 299 pixels. Optionally performs augmentation.'''   \n",
    "    #slices = [22,36,50] #Planes to slice\n",
    "    slices = np.array([base_slice,base_slice,base_slice]) #Planes to slice\n",
    "    if pad_images == True:\n",
    "        pad_max = np.max(X.shape[2:]) #Width to pad images to\n",
    "    else:\n",
    "        pad_max = 0\n",
    "    num_volumes = X.shape[0]\n",
    "    height = X.shape[1]\n",
    "    width = X.shape[2]\n",
    "    num_slices = X.shape[3]\n",
    "    X_preprocessed = np.zeros((num_volumes,target_height,target_width,3))\n",
    "    if is_training == True:\n",
    "        for i in range(num_volumes):\n",
    "            vol = np.copy(np.squeeze(X[i,:]))\n",
    "            #Flip\n",
    "            if flip == True:\n",
    "                if np.random.uniform() > 0.5:\n",
    "                    vol = np.fliplr(vol)\n",
    "                if np.random.uniform() > 0.5:\n",
    "                    vol = np.flip(vol,2)\n",
    "            #Rotate about z\n",
    "            if rotate_z == True:\n",
    "                angle = np.random.randint(-20,20)\n",
    "                for slice_num in range(num_slices):\n",
    "                    vol[:,:,slice_num] = imrotate(vol[:,:,slice_num],angle,interp='bilinear')\n",
    "            #Sample different slice in plane\n",
    "            if sample_more_slices == True:\n",
    "                slices_new = slices + np.random.randint(-5,5)\n",
    "            else:\n",
    "                slices_new = slices\n",
    "            #Crop\n",
    "            if crop_image == True:\n",
    "                image_ratio = width / height\n",
    "                target_image_ratio = target_width / target_height\n",
    "                crop_vertically = image_ratio < target_image_ratio\n",
    "                crop_width = width if crop_vertically else int(height * target_image_ratio)\n",
    "                crop_height = int(width / target_image_ratio) if crop_vertically else height\n",
    "\n",
    "                # Now let's shrink this bounding box by a random factor (dividing the dimensions by a random number\n",
    "                # between 1.0 and 1.0 + `max_zoom`.\n",
    "                max_zoom = 0.8\n",
    "                resize_factor = np.random.rand() * max_zoom + 1.0\n",
    "                crop_width = int(crop_width / resize_factor)\n",
    "                crop_height = int(crop_height / resize_factor)\n",
    "\n",
    "                # Next, we can select a random location on the image for this bounding box.\n",
    "                x0 = np.random.randint(0, width - crop_width)\n",
    "                y0 = np.random.randint(0, height - crop_height)\n",
    "                x1 = x0 + crop_width\n",
    "                y1 = y0 + crop_height\n",
    "            else:\n",
    "                x0=0;y0=0;x1=width;y1=height\n",
    "            for j in range(3):\n",
    "                if (j == 0):\n",
    "                    X_preprocessed[i,:,:,j] = imresize(pad_image(vol[slices_new[j],y0:y1, x0:x1],pad_max),(target_width,target_height))\n",
    "                if (j == 1):\n",
    "                    X_preprocessed[i,:,:,j] = imresize(pad_image(vol[slices_new[j],y0:y1, x0:x1],pad_max),(target_width,target_height))\n",
    "                if (j == 2):\n",
    "                    X_preprocessed[i,:,:,j] = imresize(pad_image(vol[slices_new[j],y0:y1, x0:x1],pad_max),(target_width,target_height))     \n",
    "                    \n",
    "    else:\n",
    "        pad_max = np.max(X.shape[2:]) #Always pad for testing\n",
    "        for i in range(num_volumes):\n",
    "            for j in range(3):\n",
    "                if (j == 0):\n",
    "                    X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,slices[j],:,:]),pad_max),(target_width,target_height))\n",
    "                if (j == 1):\n",
    "                    X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,slices[j],:,:]),pad_max),(target_width,target_height))\n",
    "                if (j == 2):\n",
    "                    X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,slices[j],:,:]),pad_max),(target_width,target_height))     \n",
    "   \n",
    "    if rescale == True:\n",
    "        X_preprocessed = X_preprocessed.astype(np.float32)\n",
    "        X_preprocessed/= 255\n",
    "        X_preprocessed -= 0.5\n",
    "        X_preprocessed *= 2.\n",
    "    return X_preprocessed\n",
    "\n",
    "def preprocess_data_coronal(X,target_height=299,target_width=299, base_slice=36,rescale=False,):\n",
    "    '''Convert each MR volume to three slices through a single plane, scales the data and resamples\n",
    "    to 299 by 299 pixels. Optionally performs augmentation.'''   \n",
    "    #slices = [22,36,50] #Planes to slice\n",
    "    slices = np.array([base_slice,base_slice,base_slice]) #Planes to slice\n",
    "    pad_max = np.max([X.shape[1],X.shape[3]]) #Width to pad images to\n",
    "    \n",
    "    num_volumes = X.shape[0]\n",
    "    height = X.shape[1]\n",
    "    width = X.shape[3]\n",
    "    num_slices = X.shape[2]\n",
    "    X_preprocessed = np.zeros((num_volumes,target_height,target_width,3))\n",
    "\n",
    "    for i in range(num_volumes):\n",
    "        for j in range(3):\n",
    "            if (j == 0):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,:,slices[j],:]),pad_max),(target_width,target_height))\n",
    "            if (j == 1):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,:,slices[j],:]),pad_max),(target_width,target_height))\n",
    "            if (j == 2):\n",
    "                X_preprocessed[i,:,:,j] = imresize(pad_image(np.squeeze(X[i,:,slices[j],:]),pad_max),(target_width,target_height))     \n",
    "   \n",
    "    if rescale == True:\n",
    "        X_preprocessed = X_preprocessed.astype(np.float32)\n",
    "        X_preprocessed/= 255\n",
    "        X_preprocessed -= 0.5\n",
    "        X_preprocessed *= 2.\n",
    "    return X_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['110411', '115320', '111312', '103414', '113619', '118932', '118730', '105115', '100307', '117122']\n",
      "['100307', '103414', '105115', '110411', '111312', '113619', '115320', '117122', '118730', '118932']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-fdabd3e6086a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0mstart_indx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mslice_num\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_vols\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mend_indx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mslice_num\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_vols\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0mX_preprocessed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_data_planar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbase_slice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mslice_indx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_indx_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mend_indx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_vols\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-71f54eb14028>\u001b[0m in \u001b[0;36mpreprocess_data_planar\u001b[0;34m(X, target_height, target_width, is_training, flip, rotate_z, base_slice, sample_more_slices, pad_images, crop_image, rescale)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m                     \u001b[0mX_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                     \u001b[0mX_preprocessed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpad_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mslices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpad_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_width\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtarget_height\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.4/dist-packages/scipy/misc/pilutil.py\u001b[0m in \u001b[0;36mimresize\u001b[0;34m(arr, size, interp, mode)\u001b[0m\n\u001b[1;32m    480\u001b[0m     \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0mts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0missubdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m         \u001b[0mpercent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m100.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m         \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpercent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib64/python3.4/site-packages/numpy/core/numerictypes.py\u001b[0m in \u001b[0;36missubdtype\u001b[0;34m(arg1, arg2)\u001b[0m\n\u001b[1;32m    759\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmro\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0missubclass\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = fetch_data(os.path.join(root_dir,'data/sims'),8)\n",
    "\n",
    "num_vols = 108\n",
    "num_train = 6\n",
    "num_test = 2\n",
    "slices_to_extract = [20,36,52]\n",
    "\n",
    "X_train = np.zeros((num_vols*num_train*len(slices_to_extract),299,299,3))\n",
    "X_test = np.zeros((num_vols*num_test*len(slices_to_extract),299,299,3))\n",
    "y_train = np.zeros((num_vols*num_train*len(slices_to_extract)))\n",
    "y_test = np.zeros((num_vols*num_test*len(slices_to_extract)))\n",
    "\n",
    "for slice_num, slice_indx in enumerate(slices_to_extract):\n",
    "    start_indx_train = slice_num * num_vols*num_train\n",
    "    end_indx_train = (slice_num+1) * num_vols*num_train\n",
    "    start_indx_test = slice_num * num_vols*num_test\n",
    "    end_indx_test = (slice_num+1) * num_vols*num_test\n",
    "    X_preprocessed = preprocess_data_planar(X,base_slice=slice_indx)\n",
    "\n",
    "    X_train[start_indx_train:end_indx_train,:] = X_preprocessed[:num_vols*num_train]\n",
    "    X_test[start_indx_test:end_indx_test,:] = X_preprocessed[num_vols*num_train:]\n",
    "    y_train[start_indx_train:end_indx_train]= y[:num_vols*num_train]\n",
    "    y_test[start_indx_test:end_indx_test]=y[num_vols*num_train:]\n",
    "\n",
    "#Clear memory\n",
    "del X,y, X_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[1400,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.inception_v3 import preprocess_input, InceptionV3\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "train_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    data_format='channels_last')\n",
    "\n",
    "validation_generator = ImageDataGenerator(\n",
    "    featurewise_center=False,\n",
    "    samplewise_center=False,\n",
    "    featurewise_std_normalization=False,\n",
    "    samplewise_std_normalization=False,\n",
    "    zca_whitening=False,\n",
    "    zca_epsilon=1e-6,\n",
    "    rotation_range=0.,\n",
    "    width_shift_range=0.,\n",
    "    height_shift_range=0.,\n",
    "    shear_range=0.0,\n",
    "    zoom_range=0.,\n",
    "    channel_shift_range=0.,\n",
    "    fill_mode='nearest',\n",
    "    cval=0.,\n",
    "    horizontal_flip=False,\n",
    "    vertical_flip=False,\n",
    "    rescale=None,\n",
    "    preprocessing_function=preprocess_input,\n",
    "    data_format='channels_last',)\n",
    "\n",
    "train_batch_size = 64\n",
    "validation_batch_size = 64\n",
    "train_examples = X_train.shape[0]\n",
    "validation_examples = X_test.shape[0]\n",
    "train_data = train_generator.flow(X_train,to_categorical(y_train,2),batch_size=train_batch_size,shuffle=True)\n",
    "validation_data = validation_generator.flow(X_test,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "\n",
    "\n",
    "#     ctr = 0\n",
    "#     for batch in train_data:\n",
    "#         im = np.squeeze(batch[0][6,:])\n",
    "#         print(im.shape)\n",
    "#         plt.imshow(im)\n",
    "#         ctr += 1\n",
    "#         if ctr > 0:\n",
    "#             break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(1-np.sum(y_train)/len(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up inception v3 for transfer learning\n",
    "base_model = InceptionV3(weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(16,activation='relu')(x)\n",
    "predictions = Dense(2,activation='softmax')(x)\n",
    "\n",
    "\n",
    "    \n",
    "model = Model(inputs=base_model.input,outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "             loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name: keras_logs/2017-09-19-09-52-16\n",
      "Epoch 1/20\n",
      "31/30 [==============================] - 42s - loss: 0.5162 - acc: 0.7668 - val_loss: 0.5591 - val_acc: 0.7438\n",
      "Epoch 2/20\n",
      "31/30 [==============================] - 41s - loss: 0.4414 - acc: 0.8085 - val_loss: 0.5790 - val_acc: 0.7052\n",
      "Epoch 3/20\n",
      "31/30 [==============================] - 41s - loss: 0.3759 - acc: 0.8483 - val_loss: 0.4741 - val_acc: 0.7886\n",
      "Epoch 4/20\n",
      "31/30 [==============================] - 41s - loss: 0.3641 - acc: 0.8501 - val_loss: 0.7486 - val_acc: 0.5247\n",
      "Epoch 5/20\n",
      "31/30 [==============================] - 41s - loss: 0.3426 - acc: 0.8626 - val_loss: 0.6645 - val_acc: 0.5864\n",
      "Epoch 6/20\n",
      "31/30 [==============================] - 41s - loss: 0.3409 - acc: 0.8682 - val_loss: 0.4892 - val_acc: 0.7886\n",
      "Epoch 7/20\n",
      "31/30 [==============================] - 41s - loss: 0.3236 - acc: 0.8667 - val_loss: 0.4617 - val_acc: 0.8117\n",
      "Epoch 8/20\n",
      "31/30 [==============================] - 41s - loss: 0.3279 - acc: 0.8719 - val_loss: 0.5789 - val_acc: 0.6821\n",
      "Epoch 9/20\n",
      "31/30 [==============================] - 41s - loss: 0.2794 - acc: 0.8948 - val_loss: 0.6963 - val_acc: 0.6065\n",
      "Epoch 10/20\n",
      "31/30 [==============================] - 51s - loss: 0.2998 - acc: 0.8856 - val_loss: 0.6696 - val_acc: 0.6250\n",
      "Epoch 11/20\n",
      "31/30 [==============================] - 41s - loss: 0.3103 - acc: 0.8684 - val_loss: 0.4522 - val_acc: 0.8364\n",
      "Epoch 12/20\n",
      "31/30 [==============================] - 41s - loss: 0.2847 - acc: 0.8930 - val_loss: 0.4260 - val_acc: 0.8302\n",
      "Epoch 13/20\n",
      "31/30 [==============================] - 41s - loss: 0.2672 - acc: 0.8928 - val_loss: 0.4261 - val_acc: 0.8194\n",
      "Epoch 14/20\n",
      "31/30 [==============================] - 41s - loss: 0.2599 - acc: 0.9109 - val_loss: 0.4185 - val_acc: 0.8241\n",
      "Epoch 15/20\n",
      "31/30 [==============================] - 41s - loss: 0.2591 - acc: 0.8975 - val_loss: 0.4730 - val_acc: 0.8349\n",
      "Epoch 16/20\n",
      "31/30 [==============================] - 41s - loss: 0.2883 - acc: 0.8863 - val_loss: 0.4224 - val_acc: 0.8164\n",
      "Epoch 17/20\n",
      "31/30 [==============================] - 41s - loss: 0.2781 - acc: 0.8789 - val_loss: 0.4585 - val_acc: 0.7932\n",
      "Epoch 18/20\n",
      "31/30 [==============================] - 41s - loss: 0.2540 - acc: 0.9041 - val_loss: 0.3820 - val_acc: 0.8534\n",
      "Epoch 19/20\n",
      "31/30 [==============================] - 41s - loss: 0.2414 - acc: 0.9113 - val_loss: 0.4293 - val_acc: 0.8117\n",
      "Epoch 20/20\n",
      "31/30 [==============================] - 41s - loss: 0.2251 - acc: 0.9183 - val_loss: 0.4449 - val_acc: 0.8056\n",
      "[[378  87]\n",
      " [ 39 144]]\n"
     ]
    }
   ],
   "source": [
    "from time import gmtime, strftime\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "now = strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "filename = 'keras_logs/'+now+'.epoch{epoch:02d}-lossval{val_loss:.2f}.hdf5'\n",
    "checkpoint = ModelCheckpoint(filepath=filename,\n",
    "                            period=10)\n",
    "\n",
    "train_steps_per_epoch = train_examples/train_batch_size\n",
    "validation_steps_per_epoch = validation_examples/validation_batch_size\n",
    "num_epochs = 20\n",
    "\n",
    "print('Model name:','keras_logs/'+now)\n",
    "history = model.fit_generator(generator = train_data,\n",
    "                           steps_per_epoch=train_steps_per_epoch,\n",
    "                           epochs = num_epochs,\n",
    "                           validation_data = validation_data,\n",
    "                           validation_steps = validation_steps_per_epoch,\n",
    "                           class_weight=[1,3],\n",
    "                            callbacks=[checkpoint])\n",
    "\n",
    "validation_data = validation_generator.flow(X_test,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "y_pred = model.predict_generator(validation_data,validation_steps_per_epoch)[:,1] > 0.5\n",
    "print(confusion_matrix(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slices complete: 0\n",
      "Slices complete: 1\n",
      "Slices complete: 2\n",
      "Slices complete: 3\n",
      "Slices complete: 4\n",
      "Slices complete: 5\n",
      "Slices complete: 6\n",
      "Slices complete: 7\n",
      "Slices complete: 8\n",
      "Slices complete: 9\n",
      "Slices complete: 10\n",
      "Slices complete: 11\n",
      "Slices complete: 12\n",
      "Slices complete: 13\n",
      "Slices complete: 14\n",
      "Slices complete: 15\n",
      "Slices complete: 16\n",
      "Slices complete: 17\n",
      "Slices complete: 18\n",
      "Slices complete: 19\n",
      "Slices complete: 20\n",
      "Slices complete: 21\n",
      "Slices complete: 22\n",
      "Slices complete: 23\n",
      "Slices complete: 24\n",
      "Slices complete: 25\n",
      "Slices complete: 26\n",
      "Slices complete: 27\n",
      "Slices complete: 28\n",
      "Slices complete: 29\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from keras import models\n",
    "#from sklearn.model_selection import accuracy\n",
    "\n",
    "model_coronal =   models.load_model('keras_logs/coronal_model.hdf5')\n",
    "model_saggital=   models.load_model('keras_logs/saggital_model.hdf5')\n",
    "#Free up some mem\n",
    "#del X_train, X_test\n",
    "X, y = fetch_data(os.path.join(root_dir,'data/sims'),8)\n",
    "y_test = y[648:]\n",
    "X_test = X[648:,:,:,:]\n",
    "del X, y\n",
    "num_slices = 30\n",
    "validation_batch_size = 64\n",
    "model_predictions_coronal = np.zeros((216,num_slices))\n",
    "model_predictions_saggital = np.zeros((216,num_slices))\n",
    "\n",
    "for i in range(num_slices):\n",
    "    #corornal\n",
    "    X_test_slice = preprocess_data_coronal(X_test,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_test_slice,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_coronal[:,i] = model_coronal.predict_generator(validation_data_for_testing,4)[:,1]\n",
    "    \n",
    "    #saggital\n",
    "    X_test_slice = preprocess_data_planar(X_test,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_test_slice,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_saggital[:,i] = model_saggital.predict_generator(validation_data_for_testing,4)[:,1]\n",
    "    print('Slices complete:',i)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144  11]\n",
      " [  9  52]]\n",
      "[[145  10]\n",
      " [  8  53]]\n",
      "0.907407407407\n",
      "0.916666666667\n",
      "(1, 216)\n",
      "[[154   1]\n",
      " [ 12  49]]\n",
      "0.939814814815\n"
     ]
    }
   ],
   "source": [
    "#y_pred1 = np.mean(model_predictions_saggital,axis=1) > 0.6\n",
    "#y_pred2 = np.mean(model_predictions_coronal,axis=1) > 0.35\n",
    "y_pred1 = (np.sum(model_predictions_saggital>0.5,axis=1) > 9)\n",
    "y_pred2 = (np.sum(model_predictions_coronal>0.5,axis=1) > 9)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(y_pred1.reshape(1,-1).shape)\n",
    "\n",
    "y_both = np.concatenate((y_pred1.reshape(1,-1), y_pred2.reshape(1,-1)),axis=0)\n",
    "y_pred_total = np.all(y_both,axis=0)\n",
    "print(confusion_matrix(y_test,y_pred_total))\n",
    "print(accuracy_score(y_test,y_pred_total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slices complete: 0\n",
      "Slices complete: 1\n",
      "Slices complete: 2\n",
      "Slices complete: 3\n",
      "Slices complete: 4\n",
      "Slices complete: 5\n",
      "Slices complete: 6\n",
      "Slices complete: 7\n",
      "Slices complete: 8\n",
      "Slices complete: 9\n",
      "Slices complete: 10\n",
      "Slices complete: 11\n",
      "Slices complete: 12\n",
      "Slices complete: 13\n",
      "Slices complete: 14\n",
      "Slices complete: 15\n",
      "Slices complete: 16\n",
      "Slices complete: 17\n",
      "Slices complete: 18\n",
      "Slices complete: 19\n",
      "Slices complete: 20\n",
      "Slices complete: 21\n",
      "Slices complete: 22\n",
      "Slices complete: 23\n",
      "Slices complete: 24\n",
      "Slices complete: 25\n",
      "Slices complete: 26\n",
      "Slices complete: 27\n",
      "Slices complete: 28\n",
      "Slices complete: 29\n"
     ]
    }
   ],
   "source": [
    "#Try test set \n",
    "\n",
    "model_coronal =   models.load_model('keras_logs/coronal_model.hdf5')\n",
    "model_saggital=   models.load_model('keras_logs/saggital_model.hdf5')\n",
    "#Free up some mem\n",
    "#del X_train, X_test\n",
    "X, y = fetch_data(os.path.join(root_dir,'data/sims'),10)\n",
    "y_test = y[864:]\n",
    "X_test = X[864:,:,:,:]\n",
    "del X, y\n",
    "num_slices = 30\n",
    "validation_batch_size = 64\n",
    "model_predictions_coronal = np.zeros((216,num_slices))\n",
    "model_predictions_saggital = np.zeros((216,num_slices))\n",
    "\n",
    "for i in range(num_slices):\n",
    "    #corornal\n",
    "    X_test_slice = preprocess_data_coronal(X_test,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_test_slice,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_coronal[:,i] = model_coronal.predict_generator(validation_data_for_testing,4)[:,1]\n",
    "    \n",
    "    #saggital\n",
    "    X_test_slice = preprocess_data_planar(X_test,base_slice = 25+i)  \n",
    "    #Redefine validation generator to reset\n",
    "    validation_data_for_testing = validation_generator.flow(X_test_slice,to_categorical(y_test,2),batch_size=validation_batch_size,shuffle=False)\n",
    "    model_predictions_saggital[:,i] = model_saggital.predict_generator(validation_data_for_testing,4)[:,1]\n",
    "    print('Slices complete:',i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[136  28]\n",
      " [  4  48]]\n",
      "[[156   8]\n",
      " [  8  44]]\n",
      "0.851851851852\n",
      "0.925925925926\n",
      "(1, 216)\n",
      "[[161   3]\n",
      " [  9  43]]\n",
      "0.944444444444\n"
     ]
    }
   ],
   "source": [
    "#y_pred1 = np.mean(model_predictions_saggital,axis=1) > 0.6\n",
    "#y_pred2 = np.mean(model_predictions_coronal,axis=1) > 0.35\n",
    "y_pred1 = (np.sum(model_predictions_saggital>0.5,axis=1) > 5)\n",
    "y_pred2 = (np.sum(model_predictions_coronal>0.5,axis=1) > 5)\n",
    "\n",
    "print(confusion_matrix(y_test,y_pred1))\n",
    "print(confusion_matrix(y_test,y_pred2))\n",
    "print(accuracy_score(y_test,y_pred1))\n",
    "print(accuracy_score(y_test,y_pred2))\n",
    "print(y_pred1.reshape(1,-1).shape)\n",
    "\n",
    "y_both = np.concatenate((y_pred1.reshape(1,-1), y_pred2.reshape(1,-1)),axis=0)\n",
    "y_pred_total = np.all(y_both,axis=0)\n",
    "print(confusion_matrix(y_test,y_pred_total))\n",
    "print(accuracy_score(y_test,y_pred_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#import matplotlib\n",
    "#import matplotlib.pyplot as plt\n",
    "print(y_test)\n",
    "plt.plot(np.linspace(25,54,30),model_predictions[n])\n",
    "plt.title('True:'+str(y_test[n])+' Predicted:'+str(y_pred[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_training(history):\n",
    "  acc = history.history['acc']\n",
    "  val_acc = history.history['val_acc']\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "  epochs = range(len(acc))\n",
    "\n",
    "  plt.plot(epochs, acc, 'r.')\n",
    "  plt.plot(epochs, val_acc, 'r')\n",
    "  plt.title('Training and validation accuracy')\n",
    "\n",
    "  plt.figure()\n",
    "  plt.plot(epochs, loss, 'r.')\n",
    "  plt.plot(epochs, val_loss, 'r-')\n",
    "  plt.title('Training and validation loss')\n",
    "  plt.show()\n",
    "\n",
    "plot_training(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Look at memory usage of all items in notebook\n",
    "import sys\n",
    "\n",
    "# These are the usual ipython objects, including this one you are creating\n",
    "ipython_vars = ['In', 'Out', 'exit', 'quit', 'get_ipython', 'ipython_vars']\n",
    "\n",
    "# Get a sorted list of the objects and their sizes\n",
    "sorted([(x, sys.getsizeof(globals().get(x))) for x in dir() if not x.startswith('_') and x not in sys.modules and x not in ipython_vars], key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
